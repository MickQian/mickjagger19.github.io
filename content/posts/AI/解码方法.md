

---
title : ''
summary : ''
tags : [""]
author : ["Mick"]
draft : true
---

## Greedy
每个时间都选择概率最高的词作为当前输出词

cons:
* 重复文本：错过了隐藏在低概率词后的高概率词


## Beam Search 波束搜索
在每个时间步保留连续的最可能的 `num_beams` 个词，并从中最终选择出概率最高的序列来降低丢失潜在的高概率序列的风险

cons: 
* 不保证找到全局最优解

## Sampling

根据当前条件概率分布随机选择输出词 $w_t$:
$$
\begin{align}
wt∼P(w∣w1:t−1)wt​∼P(w∣w1:t−1​)
\end{align}
$$
## Top-K Sampling 
概率最大的 _K_ 个词会被选出，然后这 _K_ 个词的概率会被重新归一化，最后就在这重新被归一化概率后的 _K_ 个词中采样

被 GPT-2 采用

## Top-p(Nuclear) Sampling
采样不只是在最有可能的 _K_ 个单词中进行，而是在**累积概率超过概率 _p_ 的最小单词集**中进行

## Contrastive Search
利用每个候选词的概率分布，以及候选词元与上文每个词元的相异度

效果更好

