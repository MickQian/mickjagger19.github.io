<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>DiT, Sora, and more | Mick&#39; Blog</title>
<meta name="keywords" content="Transformer, Diffusion, Attention, VideoGeneration">
<meta name="description" content="Review on DiT and sora">
<meta name="author" content="Mick">
<link rel="canonical" href="https://mickjagger19.github.io/posts/ai/models/dit-sora-and-more/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.8dd6f57454653644cba6929524e195dff93a26fa61dce2b3b2629e50b8d12816.css" integrity="sha256-jdb1dFRlNkTLppKVJOGV3/k6Jvph3OKzsmKeULjRKBY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://mickjagger19.github.io/favicon.ico">
<link rel="apple-touch-icon" href="https://mickjagger19.github.io/apple-touch-icon.png">
<link rel="alternate" hreflang="en" href="https://mickjagger19.github.io/posts/ai/models/dit-sora-and-more/">

<meta name="twitter:title" content="DiT, Sora, and more | Mick&#39; Blog" />
<meta name="twitter:description" content="Review on DiT and sora" />
<meta property="og:title" content="DiT, Sora, and more | Mick&#39; Blog" />
<meta property="og:description" content="Review on DiT and sora" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mickjagger19.github.io/posts/ai/models/dit-sora-and-more/" />
<meta property="article:section" content="posts" />
  <meta property="article:published_time" content="2024-02-19T16:23:58&#43;08:00" />
  <meta property="article:modified_time" content="2024-02-19T16:23:58&#43;08:00" />


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://mickjagger19.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "DiT, Sora, and more",
      "item": "https://mickjagger19.github.io/posts/ai/models/dit-sora-and-more/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "DiT, Sora, and more | Mick' Blog",
  "name": "DiT, Sora, and more",
  "description": "Review on DiT and sora",
  "keywords": [
    "Transformer", "Diffusion", "Attention", "VideoGeneration"
  ],
  "wordCount" : "837",
  "inLanguage": "en",
  "datePublished": "2024-02-19T16:23:58+08:00",
  "dateModified": "2024-02-19T16:23:58+08:00",
  "author":{
    "@type": "Person",
    "name": "Mick"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://mickjagger19.github.io/posts/ai/models/dit-sora-and-more/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Mick' Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://mickjagger19.github.io/favicon.ico"
    }
  }
}
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"
      integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"
        integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8"
        crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
        integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            
            
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false},
                {left: '\\(', right: '\\)', display: false},
                {left: '\\[', right: '\\]', display: true}
            ],
            
            throwOnError: false
        });
    });
</script>












































































































<link rel="stylesheet" href="/css/main.css">



<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>

</head>

<body class=" dark type-posts kind-page layout-" id="top"><script data-no-instant>
    function switchTheme(theme) {
        switch (theme) {
            case 'light':
                document.body.classList.remove('dark');
                break;
            case 'dark':
                document.body.classList.add('dark');
                break;
            
            default:
                if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
                    document.body.classList.add('dark');
                }
        }
    }

    function isDarkTheme() {
        return document.body.className.includes("dark");
    }

    function getPrefTheme() {
        return localStorage.getItem("pref-theme");
    }

    function setPrefTheme(theme) {
        switchTheme(theme)
        localStorage.setItem("pref-theme", theme);
    }

    const toggleThemeCallbacks = {}
    toggleThemeCallbacks['main'] = (isDark) => {
        
        if (isDark) {
            setPrefTheme('light');
        } else {
            setPrefTheme('dark');
        }
    }

    
    
    
    window.addEventListener('toggle-theme', function () {
        
        const isDark = isDarkTheme()
        for (const key in toggleThemeCallbacks) {
            toggleThemeCallbacks[key](isDark)
        }
    });

    
    function toggleThemeListener() {
        
        window.dispatchEvent(new CustomEvent('toggle-theme'));
    }

</script>
<script>
    
    (function () {
        const defaultTheme = 'dark';
        const prefTheme = getPrefTheme();
        const theme = prefTheme ? prefTheme : defaultTheme;

        switchTheme(theme);
    })();
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://mickjagger19.github.io/" accesskey="h" title="Mick&#39; Blog (Alt + H)">Mick&#39; Blog</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://mickjagger19.github.io/posts/" title="Posts" class="active"
                >
                <span>Posts
                </span>
                </a>
            </li>
            <li>
                <a href="https://mickjagger19.github.io/archives/" title="Archive"
                >
                <span>Archive
                </span>
                </a>
            </li>
            <li>
                <a href="https://mickjagger19.github.io/search/" title="Search (Alt &#43; /)"data-no-instant accesskey=/
                >
                <span>Search
                </span>
                </a>
            </li>
            <li>
                <a href="https://mickjagger19.github.io/tags/" title="Tags"
                >
                <span>Tags
                </span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main post">

<article class="post-single">
    <header class="post-header">
        <h1 class="post-title">DiT, Sora, and more</h1>
        <div class="post-meta"><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
       stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"
       style="user-select: text;"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"
                                        style="user-select: text;"></rect><line x1="16" y1="2" x2="16" y2="6"
                                                                                style="user-select: text;"></line><line
          x1="8" y1="2" x2="8" y2="6" style="user-select: text;"></line><line x1="3" y1="10" x2="21" y2="10"
                                                                              style="user-select: text;"></line></svg>
  <span>February 19, 2024</span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentColor"
       stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"
                                                                                         fill="none"></path><circle
          cx="12" cy="12" r="9"></circle><polyline points="12 7 12 12 15 15"></polyline></svg>
  <span>4 min</span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentColor"
       stroke-width="1" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"
                                                                                         fill="none"></path><circle
          cx="12" cy="7" r="4"></circle><path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2"></path></svg>Mick</span>

            
            
        </div>
    </header> <div class="toc side right">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#dit-design-space" aria-label="DiT Design Space">DiT Design Space</a><ul>
                        
                <li>
                    <a href="#1-patchify" aria-label="1. Patchify">1. Patchify</a></li>
                <li>
                    <a href="#2-positional-embeddings" aria-label="2. Positional Embeddings">2. Positional Embeddings</a></li>
                <li>
                    <a href="#3-transformer-blocks" aria-label="3. Transformer Blocks">3. Transformer Blocks</a><ul>
                        
                <li>
                    <a href="#in-context-conditioning" aria-label="In-context conditioning">In-context conditioning</a></li>
                <li>
                    <a href="#cross-attention-block" aria-label="Cross-attention block">Cross-attention block</a></li>
                <li>
                    <a href="#adaptie-layer-normadaln-block" aria-label="Adaptie Layer Norm(adaLN) Block">Adaptie Layer Norm(adaLN) Block</a></li></ul>
                </li>
                <li>
                    <a href="#4-transformer-decoder" aria-label="4. Transformer Decoder">4. Transformer Decoder</a></li></ul>
                </li>
                <li>
                    <a href="#sora" aria-label="Sora">Sora</a><ul>
                        
                <li>
                    <a href="#unified-representation-of-visual-data" aria-label="Unified Representation of Visual Data">Unified Representation of Visual Data</a><ul>
                        
                <li>
                    <a href="#sources" aria-label="Sources">Sources</a></li>
                <li>
                    <a href="#patch" aria-label="Patch">Patch</a></li></ul>
                </li>
                <li>
                    <a href="#scaling-transformers" aria-label="Scaling Transformers">Scaling Transformers</a></li>
                <li>
                    <a href="#data-preprocessing" aria-label="Data preprocessing">Data preprocessing</a><ul>
                        
                <li>
                    <a href="#native-size" aria-label="Native size">Native size</a></li>
                <li>
                    <a href="#native-aspect-ratios" aria-label="Native aspect ratios">Native aspect ratios</a></li></ul>
                </li>
                <li>
                    <a href="#language-understanding" aria-label="Language understanding">Language understanding</a><ul>
                        
                <li>
                    <a href="#re-captioning" aria-label="Re-captioning">Re-captioning</a></li></ul>
                </li>
                <li>
                    <a href="#prompting-with-images-and-videos" aria-label="Prompting with images and videos">Prompting with images and videos</a><ul>
                        
                <li>
                    <a href="#some-applications-not-mentioned-in-the-report" aria-label="Some applications not mentioned in the report">Some applications not mentioned in the report</a>
                </li>
            </ul>
            </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

    <div class="post-content"><blockquote>
<p>[! WARNING]
This work is in progress</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">Notations</th>
<th style="text-align:left">Meaning</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Classifier-guided Diffusion</td>
<td style="text-align:left">An implementation of Conditional Diffusion Models, which requires a classifier $\nabla_{x}p(x|y)$ to guide its reverse process</td>
<td></td>
</tr>
<tr>
<td style="text-align:left">Classifier-free Diffusion</td>
<td style="text-align:left">An implementation of Conditional Diffusion Models, which doesn&rsquo;t require a <strong>classfier</strong>, the condition serves as an input to its <strong>noise predictor</strong></td>
<td></td>
</tr>
<tr>
<td style="text-align:left">Latent Diffusion Models(LDM)</td>
<td style="text-align:left">A type of Diffusion Models where diffusion processes are done in <strong>latent space</strong></td>
<td></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td></td>
</tr>
</tbody>
</table>
<h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">¶</a></h1>
<p>Diffusion models usually choose a <strong>UNet</strong> as its backbone for Noise Predictor, first adopted by Ho et al [^1] , which was inherited from <strong>Pixel-CNN++</strong>(widely used as the generator in VAE) with a few changes. Although some works have introduced attention blocks into low-level design, its high-level remains intact.</p>
<p><strong>DiT</strong> is proposed to apply Transformer into Diffusion Models, adhering to the best practices of <strong>Vision Transformers(ViTs)</strong></p>
<p>Also, the scaling behavios of transformers is also explored in DiT</p>
<h1 id="dit-design-space">DiT Design Space<a hidden class="anchor" aria-hidden="true" href="#dit-design-space">¶</a></h1>
<table>
<thead>
<tr>
<th style="text-align:left">Notations</th>
<th style="text-align:left">Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">$C$</td>
<td style="text-align:left">the channels of input image</td>
</tr>
<tr>
<td style="text-align:left">$I$</td>
<td style="text-align:left">the dimension of $z$</td>
</tr>
<tr>
<td style="text-align:left">$z \in R^{I \times I \times C}$</td>
<td style="text-align:left">The latents, also the input of $DiT$</td>
</tr>
<tr>
<td style="text-align:left">Patch</td>
<td style="text-align:left">The unit of input.</td>
</tr>
<tr>
<td style="text-align:left">$p$</td>
<td style="text-align:left">the dimension of a single patch</td>
</tr>
<tr>
<td style="text-align:left">Classifier-free Diffusion</td>
<td style="text-align:left">An implementation of Conditional Diffusion Models, which doesn&rsquo;t require a <strong>classfier</strong>, the condition serves as an input to its <strong>noise predictor</strong></td>
</tr>
<tr>
<td style="text-align:left">Latent Diffusion Models(LDM)</td>
<td style="text-align:left">A type of Diffusion Models where diffusion processes are done in <strong>latent space</strong></td>
</tr>
</tbody>
</table>
<h2 id="1-patchify">1. Patchify<a hidden class="anchor" aria-hidden="true" href="#1-patchify">¶</a></h2>
<p><strong>Patchify</strong> is the first layer of DiT, which converts the spatial input $z$ into a sequence to $T$ tokens, each of dimension $d$:
$$
z \in R^{I \times I \times C} \to T \cdot Token
$$
where:</p>
<ul>
<li>$Token \in R^{p \times p \times C}$</li>
<li>$T = (\frac{I}{p})^2$</li>
</ul>
<h2 id="2-positional-embeddings">2. Positional Embeddings<a hidden class="anchor" aria-hidden="true" href="#2-positional-embeddings">¶</a></h2>
<p>Following patchify, we apply standard ViT <strong>frequency-based positional embeddings</strong> (the sine-cosine version) to all input tokens: $Token \to Patch$</p>
<h2 id="3-transformer-blocks">3. Transformer Blocks<a hidden class="anchor" aria-hidden="true" href="#3-transformer-blocks">¶</a></h2>
<p>Following patchify, the input tokens are processed by a sequence of transformer blocks.</p>
<h3 id="in-context-conditioning">In-context conditioning<a hidden class="anchor" aria-hidden="true" href="#in-context-conditioning">¶</a></h3>
<p>In addition to noised image inputs, diffusion models sometimes process additional conditional information:</p>
<ul>
<li>$t$: noise timestamps (of DDPM)</li>
<li>$c$: class labels c(of input images)</li>
<li>natural language description(or caption)</li>
</ul>
<p>The conditions are represented as additional $Token$s, <strong>appened</strong> to the [input sequence](## 2. Positional Embeddings)</p>
<h3 id="cross-attention-block">Cross-attention block<a hidden class="anchor" aria-hidden="true" href="#cross-attention-block">¶</a></h3>
<p>The conditional tokens are send to the cross-attention block of transformer block</p>
<h3 id="adaptie-layer-normadaln-block">Adaptie Layer Norm(adaLN) Block<a hidden class="anchor" aria-hidden="true" href="#adaptie-layer-normadaln-block">¶</a></h3>
<p>The <strong>Adaptive Layer Norm</strong> replaces the standard layer norm</p>
<blockquote>
<p>[! NOTE]
To be completed</p>
</blockquote>
<h2 id="4-transformer-decoder">4. Transformer Decoder<a hidden class="anchor" aria-hidden="true" href="#4-transformer-decoder">¶</a></h2>
<p>After the transformer blocks, a <strong>transformer decoder</strong> is reponsible for decoding the each latent token back to tensor of size $p \times p \times C$.</p>
<p>The decoder is simply a <strong>standrad linear layer</strong></p>
<h1 id="sora">Sora<a hidden class="anchor" aria-hidden="true" href="#sora">¶</a></h1>
<p>The following is some major takeaways of <a href="https://openai.com/research/video-generation-models-as-world-simulators">the tenichal report of Sora</a></p>
<p>Sora is a diffusion model/diffusion transformer based on <strong>DiT</strong></p>
<h2 id="unified-representation-of-visual-data">Unified Representation of Visual Data<a hidden class="anchor" aria-hidden="true" href="#unified-representation-of-visual-data">¶</a></h2>
<p>The major part of the technial report is about the <strong>Unified Representation</strong>, which is the training data of Sora</p>
<h3 id="sources">Sources<a hidden class="anchor" aria-hidden="true" href="#sources">¶</a></h3>
<blockquote>
<p>We take inspiration from large language models which acquire generalist capabilities by training on internet-scale data</p>
</blockquote>
<p>Based on the description, Sora might crawl a huge amount of data from internet</p>
<h3 id="patch">Patch<a hidden class="anchor" aria-hidden="true" href="#patch">¶</a></h3>
<p>Following the text token concept of LLM, and patch concept from [DiT](##1. Patchify), Sora has visual <em>patches</em>.</p>
<p>The transformation of videos into patches went through 2 steps:</p>
<ol>
<li>Compress videos into lower-dimensional latents</li>
<li>Decompose the latents into <strong>spacetime</strong> patches</li>
</ol>
<blockquote>
<p>[! TIP]
<strong>spacetime</strong> implies that the tokens are embedded with timestep information</p>
</blockquote>
<p>While the original DiT tokens are fixed-sized based on the size of the latents, the <em>spacetime</em> patches used by Sora is derived from videos/images of <strong>variable resolutions, durations and aspect ratios</strong>. This gives huge flexibility in inference time, since the output is formed with any patches you like.</p>
<h2 id="scaling-transformers">Scaling Transformers<a hidden class="anchor" aria-hidden="true" href="#scaling-transformers">¶</a></h2>
<p>They find transformers scaled effectively as video models, same as in other domains, including language modeling,<a href="https://openai.com/research/video-generation-models-as-world-simulators#fn-13">13</a>,<a href="https://openai.com/research/video-generation-models-as-world-simulators#fn-14">14</a> computer vision,<a href="https://openai.com/research/video-generation-models-as-world-simulators#fn-15">15</a>,<a href="https://openai.com/research/video-generation-models-as-world-simulators#fn-16">16</a>,<a href="https://openai.com/research/video-generation-models-as-world-simulators#fn-17">17</a>,<a href="https://openai.com/research/video-generation-models-as-world-simulators#fn-18">18</a> and image generation.<a href="https://openai.com/research/video-generation-models-as-world-simulators#fn-27">27</a>,<a href="https://openai.com/research/video-generation-models-as-world-simulators#fn-28">28</a>,<a href="https://openai.com/research/video-generation-models-as-world-simulators#fn-29">29</a></p>
<h2 id="data-preprocessing">Data preprocessing<a hidden class="anchor" aria-hidden="true" href="#data-preprocessing">¶</a></h2>
<h3 id="native-size">Native size<a hidden class="anchor" aria-hidden="true" href="#native-size">¶</a></h3>
<p>Different from prior approaches, which crops videos/images to standard size(e.g., 4 seconds videos at 256 * 256 resolution), they find that training on data at its <strong>native size</strong> benefits.</p>
<h3 id="native-aspect-ratios">Native aspect ratios<a hidden class="anchor" aria-hidden="true" href="#native-aspect-ratios">¶</a></h3>
<p>They empirically find that training on videos at their native aspect ratios improves composition and framing. The model trained on square crops sometimes generates videos where the subject is only <strong>partially</strong> in view.</p>
<h2 id="language-understanding">Language understanding<a hidden class="anchor" aria-hidden="true" href="#language-understanding">¶</a></h2>
<p>The language-understanding-ability is a crucial part of text-to-video models, as text is the major input</p>
<h3 id="re-captioning">Re-captioning<a hidden class="anchor" aria-hidden="true" href="#re-captioning">¶</a></h3>
<p><strong>Re-captioning</strong> is a technique to generate descriptive captions for images/videos with the help of a <strong>highly descriptive captioner model</strong></p>
<p>First introduced in the training of DALL$\cdot$E, it is used in Sora, where GPT serves the role of <strong>captioner</strong>, who <em>turn short user prompts into longer detailed captions</em></p>
<h2 id="prompting-with-images-and-videos">Prompting with images and videos<a hidden class="anchor" aria-hidden="true" href="#prompting-with-images-and-videos">¶</a></h2>
<p>Being abled to be prompted with inputs other than text, including images and videos, Sora can perform a wide range of image and video editing tasks.</p>
<h3 id="some-applications-not-mentioned-in-the-report">Some applications not mentioned in the report<a hidden class="anchor" aria-hidden="true" href="#some-applications-not-mentioned-in-the-report">¶</a></h3>
<p>Based on the presented applications, Sora might be able to do the tasks of:</p>
<ul>
<li>video generation conditioned on text/image: generate videos based on the given future/previous text and image</li>
<li></li>
</ul>
<blockquote>
<p> Model and implementation details are not included in this report.
 &ndash; video-generation-models-as-world-simulators</p>
</blockquote>


    </div>

    <footer class="post-footer"><ul class="post-tags"><li>
                <a href="https://mickjagger19.github.io/tags/transformer/">Transformer</a>
            </li><li>
                <a href="https://mickjagger19.github.io/tags/diffusion/">Diffusion</a>
            </li><li>
                <a href="https://mickjagger19.github.io/tags/attention/">Attention</a>
            </li><li>
                <a href="https://mickjagger19.github.io/tags/videogeneration/">VideoGeneration</a>
            </li></ul>
<nav class="paginav">
    <a class="prev" href="https://mickjagger19.github.io/posts/music/my-gears/">
    <span class="title">
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
           stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
           class="feather feather-arrow-left" style="user-select: text;"><line x1="19" y1="12" x2="5" y2="12"
                                                                               style="user-select: text;"></line><polyline
              points="12 19 5 12 12 5" style="user-select: text;"></polyline></svg>&nbsp;
    </span>
        <br>
        <span>My Gears</span>
    </a>
    <a class="next" href="https://mickjagger19.github.io/posts/ai/models/mamba/">
    <span class="title">
      &nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
                 stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                 class="feather feather-arrow-right" style="user-select: text;"><line x1="5" y1="12" x2="19" y2="12"
                                                                                      style="user-select: text;"></line><polyline
            points="12 5 19 12 12 19" style="user-select: text;"></polyline></svg>
    </span>
        <br>
        <span>Mamba</span>
    </a>
</nav>

    </footer>
    <div class="comments-separator"></div>
</article>
    </main>
    
<footer class="footer">
  <span>&copy; 2024 <a href="https://mickjagger19.github.io/">Mick&#39; Blog</a></span><span style="display: inline-block; margin-left: 1em;">
    <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a>
  </span>
  <span style="display: inline-block; margin-left: 1em;">
    Powered by
    <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
    <a href="https://github.com/reorx/hugo-PaperModX/" rel="noopener" target="_blank">PaperModX</a>
  </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
    <path d="M12 6H0l6-6z" />
  </svg>
</a>

<script>
  (function() {
     
    const disableThemeToggle = '' == '1';
    if (disableThemeToggle) {
      return;
    }

    let button = document.getElementById("theme-toggle")
    
    button.removeEventListener('click', toggleThemeListener)
    
    button.addEventListener('click', toggleThemeListener)
  })();
</script>

<script>
  (function () {
    let menu = document.getElementById('menu')
    if (menu) {
      menu.scrollLeft = localStorage.getItem("menu-scroll-position");
      menu.onscroll = function () {
        localStorage.setItem("menu-scroll-position", menu.scrollLeft);
      }
    }

    const disableSmoothScroll = '' == '1';
    const enableInstantClick = '' == '1';
    
    if (window.matchMedia('(prefers-reduced-motion: reduce)').matches || disableSmoothScroll || enableInstantClick) {
      return;
    }
    
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener("click", function (e) {
        e.preventDefault();
        var id = this.getAttribute("href").substr(1);
        document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
          behavior: "smooth"
        });
        if (id === "top") {
          history.replaceState(null, null, " ");
        } else {
          history.pushState(null, null, `#${id}`);
        }
      });
    });
  })();
</script>
<script>
  var mybutton = document.getElementById("top-link");
  window.onscroll = function () {
    if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
      mybutton.style.visibility = "visible";
      mybutton.style.opacity = "1";
    } else {
      mybutton.style.visibility = "hidden";
      mybutton.style.opacity = "0";
    }
  };
</script>
<script>
  if (window.scrollListeners) {
    
    for (const listener of scrollListeners) {
      window.removeEventListener('scroll', listener)
    }
  }
  window.scrollListeners = []
</script>



<script src="/js/medium-zoom.min.js" data-no-instant
></script>
<script>
  document.querySelectorAll('pre > code').forEach((codeblock) => {
    const container = codeblock.parentNode.parentNode;

    const copybutton = document.createElement('button');
    copybutton.classList.add('copy-code');
    copybutton.innerText = 'copy';

    function copyingDone() {
      copybutton.innerText = 'copied!';
      setTimeout(() => {
        copybutton.innerText = 'copy';
      }, 2000);
    }

    copybutton.addEventListener('click', (cb) => {
      if ('clipboard' in navigator) {
        navigator.clipboard.writeText(codeblock.textContent);
        copyingDone();
        return;
      }

      const range = document.createRange();
      range.selectNodeContents(codeblock);
      const selection = window.getSelection();
      selection.removeAllRanges();
      selection.addRange(range);
      try {
        document.execCommand('copy');
        copyingDone();
      } catch (e) { };
      selection.removeRange(range);
    });

    if (container.classList.contains("highlight")) {
      container.appendChild(copybutton);
    } else if (container.parentNode.firstChild == container) {
      
    } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
      
      codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
    } else {
      
      codeblock.parentNode.appendChild(copybutton);
    }
  });
</script>




<script>
  
  
  (function() {
    const enableTocScroll = '1' == '1'
    if (!enableTocScroll) {
      return
    }
    if (!document.querySelector('.toc')) {
      console.log('no toc found, ignore toc scroll')
      return
    }
    

    
    const scrollListeners = window.scrollListeners
    const headings = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id]');
    const activeClass = 'active';

    
    let activeHeading = headings[0];
    getLinkByHeading(activeHeading).classList.add(activeClass);

    const onScroll = () => {
      const passedHeadings = [];
      for (const h of headings) {
        
        if (getOffsetTop(h) < 5) {
          passedHeadings.push(h)
        } else {
          break;
        }
      }
      if (passedHeadings.length > 0) {
        newActiveHeading = passedHeadings[passedHeadings.length - 1];
      } else {
        newActiveHeading = headings[0];
      }
      if (activeHeading != newActiveHeading) {
        getLinkByHeading(activeHeading).classList.remove(activeClass);
        activeHeading = newActiveHeading;
        getLinkByHeading(activeHeading).classList.add(activeClass);
      }
    }

    let timer = null;
    const scrollListener = () => {
      if (timer !== null) {
        clearTimeout(timer)
      }
      timer = setTimeout(onScroll, 50)
    }
    window.addEventListener('scroll', scrollListener, false);
    scrollListeners.push(scrollListener)

    function getLinkByHeading(heading) {
      const id = encodeURI(heading.getAttribute('id')).toLowerCase();
      return document.querySelector(`.toc ul li a[href="#${id}"]`);
    }

    function getOffsetTop(heading) {
      if (!heading.getClientRects().length) {
        return 0;
      }
      let rect = heading.getBoundingClientRect();
      return rect.top
    }
  })();
  </script>

</body>

</html>
