<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AIs on Blog of Mick</title>
    <link>https://mickjagger19.github.io/ai/</link>
    <description>Recent content in AIs on Blog of Mick</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <atom:link href="https://mickjagger19.github.io/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/agent/agent-%E7%9A%84%E5%BA%94%E7%94%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/agent/agent-%E7%9A%84%E5%BA%94%E7%94%A8/</guid>
      <description> Key Introduction points Multi-Agent Architecture SOP: Standard Operating Procedural multi, to maximum the model ability In IDE: full aware of the intention, automation &amp;amp; autonomous Sensory Engine: collect user actions in every way Intention: guess the potential intention of the user( debug, jump to sources, build/run/deploy, profile) Workflow/Chain: Routine automation COI: framework in Rust/TS/WASM to support effectively setup LLM workflow with code or DSL POCs: git msg summarize/auto bugfixing/creating project directory/fix bug and show in a diff editor RAG 基于更多信息/减少幻觉/提升生产力和内容质量 knowledge: chunked codebase search: hybrid(lexical, semantical) IDE 文件树 外部数据库 或 模型参数中 保存有流行项目 文件夹的配置 返回后，将配置解析为 in-memory tree 递归调用 sandbox 的 terminal， 执行 mkdir/ touch 等指令，完成项目的创建 </description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/agent/llm-powered-auto-agent-a-survey/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/agent/llm-powered-auto-agent-a-survey/</guid>
      <description>本文的讨论主要以 不对 LM 结构和参数进行改造 为前提，因此对于涉及模型改造的方法会一笔带过
With the fast progress of LM, agents with LM as controller has extended the ability of LM, from generating text/stories/reports/essay, to solving comprehensive real-world problems
Glossary 词汇表 Introduction 背景介绍 What is an LM-Powered Agent ? Autonomous Agent(自主代理) 是能够感知环境、在现实世界中执行自主、有目的的行动的系统
针对 Autonomous Agent 的研究可以追溯到 上世纪 90年代。早期的研究只停留于理论阶段，直到最近十年才开始出现基于机器人/自动驾驶的初级 Auto-Agent 实验
最近半年（2023/4 ~ now） Auto-Agent 的一些实验项目(Auto-GPT, BabyAGI, etc) 突然获得了极大的关注度，最主要的原因是 ChatGPT 等大语言模型能力的迅速提升，使 将LM作为核心控制器的 Agent 的能力也随之大幅提高，从而使一些更复杂问题的解决成为可能。一般也称这种能力为 Weak AGI
其中最具有代表性的一些项目有：
Auto-GPT: 基于 External Commands 和 Vector Database 实现的 LM Auto-Agent，更侧重于使用各种外部功能实现更 General 的目标 HuggingGPT: 更强大的外部工具：多模态、领域专业的AI工具，聚焦于 解决多模态任务 chemcrow： 侧重于使用化学工具，解决 推理密集型 的化学任务 How does it work 它是怎么工作的？ 以 Auto-GPT 官方提供的 Demo 为例：</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/agent/rag/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/agent/rag/</guid>
      <description>metric:
perplexity downstream accuracy 准备步骤 vector store, index: embedded vector -&amp;gt; index 的倒排索引 为了控制取出文档的大小和精准性，需要做文本切分 split by char MarkdownHeader HTMLHeaderText Program Analysis to extract the semantics retrieval: (可能涉及 rerank) metric: nDCG@3/ lexical search score + semantic search score 算法：convex combination &amp;gt; RRF(Hybrid search, 只考虑排序位置，忽略排序中数据对应的分数) &amp;gt; bm25 &amp;gt; knn convex combination: 两个不同检索方式得到的召回数据，分数范围不一致，因此需要统一的分数评价体系 scaling: standard, min_max LLM: 方式： concatenation / post-fusion： 生成多个回答，选一个 / concat + PF： 最可靠 K 轮 问答 * (1 次 K 篇 文档） retrieval: optional pipeline 给定输入x 可能有 pre process: 口语化过滤，生成多个 queries 以 x 为输入，对知识库检索，得到候选 topk Zi 拼接x，Z * i (s)，得到输入序列 送入encoder，得到输出(s) 如果得到多个输出，送入answer pool 进行排序 How to retrieve Retriever train 训练 retriever，损失函数可以为 选中期望目标 的概率</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/attention-is-all-you-need/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/attention-is-all-you-need/</guid>
      <description>Recurrent Neural Network Seq2Seq
Cons:
阻碍并行化 对长距离有依赖 Encoder Embedding word embedding positional encoding N times(usually 6) Multi-head attention: n * d add-norm(skip-connection and softmax) feed-forward add-norm Decoder ![[Pasted image 20230510232321.png]]
Embedding word embedding positional encoding N times(usually 6) Masked-multi layer self-attention ![[Pasted image 20230510231445.png]] 将没有翻译过的单词(&amp;gt;= i) mask 起来 add-norm non-self attention: 输入为 Encoder 的直接输出 好处：每一位单词都可以利用到 Encoder 所有单词的信息 (这些信息无需 Mask) add-norm feed feed-forward add-norm linear softmax Query, Key, Value Attention define:</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/autonomous-agi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/autonomous-agi/</guid>
      <description>Autonomous Agent framework
AutoGPT 记忆 + 工具
核心: Prompt Loop:
组装 Command Prompt， 传入 得到 Next Step Command 执行 Command 得到 Result，作为 Command Prompt 的元素之一 重复 1 Command Prompt Demand Name Role Goal Commands Performance Evaluation: 作为提醒 Continuously review and analyze your actions to ensure you are performing to the best of your abilities. . Constructively self-criticize your big-picture behavior constantly. Reflect on past decisions and strategies to refine your approach.</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/cnn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/cnn/</guid>
      <description>NiN Inception concat channels of:
convs pool ![[Pasted image 20230618142549.png]] Yolo Unet Down sampling: (conv, relu , max-pool) * 4 times increase channels Up sampling: transpose conv on skip-connect concated features , pool shrink channels Style Transfer J = Content loss + Style loss C, S, G Content loss: loss between G and C， using pre-trained ConvNet(E.g., VGG) Style loss: loss between styles of G and S * Style 的定义：特征里，不同通道之间的互相关性 *</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/dive-into-transformers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/dive-into-transformers/</guid>
      <description>Attention Q: T, d_attn K: T, d_attn V: T, d_attn ab cb =&amp;gt; ac ac * cb =&amp;gt; ab
Q, K, V 都是 d_attn 隐空间的特征表示
关注度，感兴趣程度，匹配程度
QKt 可以理解为，求两个（自注意力时为一个） latent space 的两个 特征 的相对关注程度(T, T) 得到（相对）注意力后，与 V 相乘，得到加入 K 对 Q 的关注内容的 新特征表示
Question： 类似于code book？
其后往往接一个全连接层，投影回原来的 d_model 空间
总的来说，
Cross-Attention 可以加入 k 对 q 中内部结构的感兴趣内容（是人话吗） 自注意力可以使输出的特征更关注其自身结构，更自洽 总的来说，Attention 向 q 中 加入了 k 的要求（或者是 k 的信息）</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/dl-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/dl-theory/</guid>
      <description></description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/kaggle/models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/kaggle/models/</guid>
      <description>Classification KNN K-d Tree locality sensitive hashing Support Vector Machine Decision Tree Random Forest Perceptron </description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/kaggle/tricks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/kaggle/tricks/</guid>
      <description>Normalize Apply one-hot encoding to categorical column
Outliers 甄别和去除 补全 Missings 增添 Features 观察，选择和结果相关性较高的feature(for training) object category the categorical titles to ordinal ![[Pasted image 20230623112408.png]] numeric Age -&amp;gt; AgeBand Fare -&amp;gt; Fare Ordinal train_df[[&amp;#39;Pclass&amp;#39;, &amp;#39;Survived&amp;#39;]].groupby([&amp;#39;Pclass&amp;#39;], as_index=False) </description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/misc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/misc/</guid>
      <description>logits 对数分数
cross entropy 衡量两个 distribution 分布之间的一致程度
embedding = encode ?
prior: $p(x | \theta$) 历史 -&amp;gt; 因 posterior: $p(\theta)$ 果 -&amp;gt; 因 likelihood: $p(\theta | x)$ 因 -&amp;gt; 果
Bayes </description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/ml-ops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/ml-ops/</guid>
      <description>步骤 Scoping Data Model Deployment
data drift: distribution of data(x) changed concept drift: map of data(x-&amp;gt;y) changed
Deployment key takeaway: control the degree of automation shadow mode: introduce human judgement canary deployment: 试探，扩大 traffic blue green deployment: old -&amp;gt; blue, new -&amp;gt; green, easy to rollback
Monitoring dashboard</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/model/</guid>
      <description>速记 mlp: Flatten + FAF
CLIP 训练： text encoder, image encoder, contrastive loss, joint multimodal embedding 推理： labels + template -&amp;gt; text encoder, similarity with encoded image
Dall-E LeNet AlexNet 2012 ![[Pasted image 20230609205327.png]] 类似于 LeNet:
AlexNet: 8 层， C(M)C(M)CCC(M)FFF, 五个卷积层、两个全连接隐藏层和一个全连接输出层，使用 ReLU LeNet: 5层， C(M)C(M)FFF, 两个卷积层两个全连接隐藏层和一个全连接输出层，Sigmoid ResNet ![[Pasted image 20230609205940.png]]
DenseNet 输出是 连接， 而不是 相加，因此每一时刻的输出都与此前所有层的输出相联系 使用过渡层： 1 * 1 , stride = 2 的卷积层 减少通道数，控制模型复杂度
GRU 非循环神经网络，由于矩阵的连续乘积，可以导致 梯度消失 等问题
reset gate: 控制过去状态的数量 update gate: 控制新状态中的旧状态副本数量 ，剩余为新隐状态 $$ \begin{align} R_{t} = \sigma(X_{t}W_{xr} + H_{t-1}W_{hr} + b_{r}) \ Z_{t} = \sigma(X_{t}W_{xz} + H_{t-1}W_{hz} + b_{z}) \</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/my-music-transformer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/my-music-transformer/</guid>
      <description>Glossaries Dynamic: primer: 印子，作为基础 pattern timing and pitch JSB Chorale
Encode Methods Analogies: lower-dimensional: Codes/Encodings/Representations/Style/Feature/Bottleneck? in the latent space
Transformer Encoder bi-directional auto-regerssive Auto Encoder encode at once Decoder uni directional LSTM 问题： 较短时间内还较合理，在更长的时间维度上，没有整体性
Performance RNN, an LSTM https://magenta.tensorflow.org/performance-rnn
Vanilla Transformer Music Transformer https://magenta.tensorflow.org/music-transformer Play with a consistent theme
Position Representations RNN Approach: through their recurrence over the positions in their input CNN: apply kernels, choose with parameters 为了不止依赖于 sin 函数，使用了一种能够表示两个序列中的位置距离的 representations</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/rnn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/rnn/</guid>
      <description>目标:
自回归模型：对自己执行回归 $P(x_t|x_{t-1},&amp;hellip;,x_1)$ Latent autoregressive models 引入 latent variable $h_t$：作为总结 for X, y in train_iter: // X: 输入, y: 标签 trainer.zero_grad() // 将net输出与y求loss l = loss(net(X), y) // 对loss进行反向传播 l.sum().backward() trainer.step() k-step ahead prediction: 错误的累积
NLP vocab: token 的映射 corpus: token 的频率 map
频率最高的词: stop words，可以被过滤 词频衰减很快 拉普夫定律 拉普拉斯
Optimizer adam: sgd优化器
循环神经网络 交叉熵：信息论 perplexity: 一个序列中 n 个词元的交叉熵损失的平均值，用于评价 LM 的性能
梯度裁剪: 梯度爆炸： 梯度消失：
animator：</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/svm-support-vector-machine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/svm-support-vector-machine/</guid>
      <description>Glossary Norm 范数 向量范数： 向量大小 1-范数：各维元素的绝对值之和 2-范数：欧几里得范数，平方和开方
小样本方法 一个目标是对新样本数据进行 二分类 的（线性）、有监督、深度学习模型 凸优化问题的解是全局最优
场景：
测试数据 线性可分 ：求出超平面、支持向量，约束为硬间隔尽量大。只有此时才为线性模型，即线性可分 VM 测试数据 近似线性可分 ：软间隔最大化，引入松弛因子，线性 VM 测试数据 线性不可分 ： 引入核函数，投射到高维空间，非线性 VM 间隔最大化的目的：基于误分类最小策略，求得的超平面构成最优分离，泛化能力最强
Linear 求： 间隔最大化 ：正负超平面 的距离最大 $S = \frac{1}{2} || \omega^{2} || (1)$
$s.t.\ \ y * (wx + b) &amp;gt;= 1 (2)$
Lagrange multipliers 寻找多元函数在一组约束下的极值的方法 通过引入拉格朗日乘子，可将有 $d$ 个变量与 $k$ 个约束条件的最优化问题转化为具有 $d+k$ 个变量的无约束优化问题求解.
简单推导： 设函数为$f(x)$，约束为 $g(x) \le0$
如果是等式约束： g(x) == 0 要使多元函数取得极值，极值点 $x^$ 对于函数和约束的梯度必定同向（函数的等高线与约束线相切） 则存在 $\lambda$ 使得: $\nabla f(x^) + \lambda\nabla g(x^) = 0$ 拉格朗日函数： $L(x, \lambda) = f(x) + \lambda g(x)$ 可以看出， 拉格朗日函数对 $x$ 的偏导 在 $x^$ 处为 0，充分且必要关系，因此问题转换为 求 拉格朗日函数的极值（无约束优化）</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/techniques/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/techniques/</guid>
      <description>Regularization 正则化，降低模型复杂度，防止 overfitting
tan h: 当 |x| 比较小 时，接近线性网络
复杂度的衡量： * 参数数量 * 参数绝对值
手段：
向损失函数中引入正则项，将模型参数的范数作为惩罚 Dropout: 训练时，随机屏蔽（置0）并对结果进行 scale 原理：Don&amp;rsquo;t rely on any one feature(neuron), spread out weights 随机淘汰网络中的一些单元，因此训练时，每层不会对任意一个神经元施加 太多权重，这种分散权重的方式防止了过拟合 迫使同层节点对输出承担或多或少的责任，增强模型的泛化性，因为它不会太依赖某些局部的特征 Data augmentation 增加数据集的泛化性 Early stopping 在权重overfit之前结束，但 error 较高 Normalize 对于随机输入数据，会导致成本函数对每个维度的scale 不一致(elongated)，导致参数调整出现很多 oscillate
z-score min-max ![[Pasted image 20230510221729.png]] softmax: normalized exponential function Batch Norm 对每一批训练数据进行归一化，
effect:
reduce shift on train data 增加模型的鲁棒性，提升训练速度 在 z/a 上作用
why work?
learning on shifting input distribution: 偏移在神经网络中会产生累积，导致后面的层的输入不稳定 Layer Norm 不是全量数据集，因为容易过拟合</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/thesis/bert/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/thesis/bert/</guid>
      <description></description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/thesis/diffusion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/thesis/diffusion/</guid>
      <description>forward: reverse: 利用 guidance(文本等)，去除噪声
guidance: * image classifier * image-&amp;gt;txt model
ddpm：
预测目标 变成 预测噪声(的正态分布) 不需要预测方差，只需要均值 improved ddpm: 学习方差 添加噪声的schedule : 线性 -&amp;gt; 余弦 增加模型尺寸 Diffusion model beats GAN: 继续加尺寸，attention 加大加宽，single-scale attention -&amp;gt; multi-scale attention adaptive group normalization: 以步数为依据的归一化 classifier guidance: 图片更逼真，步数更少 Classifier Guided Diffusion: 同时训练 Classifier，用于图像分类 反向过程中，把 Xt 扔给 Classifier，输出一个交叉熵，得到 Gradient（暗含图像生成的目标：有没有含有某个物体）， 帮助采样
利用了额外的模型，训练成本高且不可控
Classifier-Free guidance: 训练时，基于有无监督信号生成两个输出，得到输出之间的相似度，反向过程的时候 进行 apply
diffusion 和 vae 的区别：
编码器目标不同：噪声 vs 特征 bottleneck 尺寸较大 多步生成 </description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/thesis/vae/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/thesis/vae/</guid>
      <description>AE: X-&amp;gt; Encoder -&amp;gt; Feature(Bottleneck) -&amp;gt; Decoder -&amp;gt; X&#39;
DAE: corrupt X，降低图片的冗余度（图片的冗余性一般都很高）
以上模型的 Feature 都来自于 图片的编码，而不是源于 Sampling。有了生成随机 Feature Feature的手段（ Sample） 就可以重建图像
VAE: X -&amp;gt; Encoder -&amp;gt; predict Gaussian Distribution -&amp;gt; sample a feature from distribution -&amp;gt; Decoder -&amp;gt; X&#39;
VAE 的 distribution 学习难度大，图像尺寸局限（不好做大）
VQVAE: 引入 CodeBook(聚类中心)，把特征转换成更稳定的特征（但同时失去了随机采样的随机性） X -&amp;gt; Encoder -&amp;gt; Feature -&amp;gt; CodeBook -&amp;gt; Quantized Feature -&amp;gt; Decoder -&amp;gt; X&#39;
pixel CNN
VQVAE2:
层级式 引入 attention, 根据 codebook 学习 prior: Pixel CNN Dall E 2 两阶段：</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/thesis/vilt-vision-and-language-transformer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/thesis/vilt-vision-and-language-transformer/</guid>
      <description>Modality Interaction: 模态融合
点乘 简单神经网络 ![[Pasted image 20230618152658.png]] transformer input: * word embedding * classifier token * linear projection of patches(with encoding)
word patch alignment：</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/thesis/vit-vision-transformer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/thesis/vit-vision-transformer/</guid>
      <description>image -&amp;gt; txt
transformer 应用于 CV 领域 patch : 16 * 16 图片 -&amp;gt; n * n 个 patch
特殊的 positional encoding: ![[Pasted image 20230618151346.png]] 对patch按顺序进行编号，将编号通过查表
转换为 embedding，sum
extra learnable token</description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid>
      <description>机器学习的种类：
神经网络 传统机器学习: SVM 决策树，随机森林 Activation Function 激活函数 非线性变换
sigmoid tanh relu prelu elu maxout Vanishing/Exploding Gradients 原因：梯度相乘带来的收敛/发散
手段： * 正确的权重初始化
Overfitting cause: 数据/模型复杂度 比 过小 数据规模越小，泛化性越差，会导致数据集中的共有的/非泛化特征被学习
在相对较少的数据集上训练大型网络 为了防止 过拟合，可以从 数据集/模型训练两个角度思考
减少参数
惩罚复杂性: weight decay
$Loss = MSE + wd * sum(w^2) $ 把参数的norm加入 Loss 函数中(l2 norm) 如何决定 wd(weight decay)? 0.1 左右 ensemble: 在同一数据集上拟合不同模型，对每个模型的预测取平均值
问题：时间长 Gram Matrix 半正定，核函数
Logistic regression </description>
    </item>
    <item>
      <title></title>
      <link>https://mickjagger19.github.io/ai/%E8%A7%A3%E7%A0%81%E6%96%B9%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mickjagger19.github.io/ai/%E8%A7%A3%E7%A0%81%E6%96%B9%E6%B3%95/</guid>
      <description>Greedy 每个时间都选择概率最高的词作为当前输出词
cons:
重复文本：错过了隐藏在低概率词后的高概率词 Beam Search 波束搜索 在每个时间步保留连续的最可能的 num_beams 个词，并从中最终选择出概率最高的序列来降低丢失潜在的高概率序列的风险
cons:
不保证找到全局最优解 Sampling 根据当前条件概率分布随机选择输出词 $w_t$: $$ \begin{align} wt∼P(w∣w1:t−1)wt​∼P(w∣w1:t−1​) \end{align} $$
Top-K Sampling 概率最大的 K 个词会被选出，然后这 K 个词的概率会被重新归一化，最后就在这重新被归一化概率后的 K 个词中采样
被 GPT-2 采用
Top-p(Nuclear) Sampling 采样不只是在最有可能的 K 个单词中进行，而是在累积概率超过概率 p 的最小单词集中进行
Contrastive Search 利用每个候选词的概率分布，以及候选词元与上文每个词元的相异度
效果更好</description>
    </item>
  </channel>
</rss>
