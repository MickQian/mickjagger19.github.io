<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DeepLearning on Mick&#39; Blog</title>
    <link>https://mickjagger19.github.io/tags/deeplearning/</link>
    <description>Recent content in DeepLearning on Mick&#39; Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 12 Jan 2024 20:22:11 +0800</lastBuildDate><atom:link href="https://mickjagger19.github.io/tags/deeplearning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Techniques of Training NNs</title>
      <link>https://mickjagger19.github.io/posts/ai/techniques-of-training-nns/</link>
      <pubDate>Fri, 12 Jan 2024 20:22:11 +0800</pubDate>
      
      <guid>https://mickjagger19.github.io/posts/ai/techniques-of-training-nns/</guid>
      <description>Describe and compare some common tricks of training NNs</description>
      <content:encoded><![CDATA[<h2 id="regularization">Regularization</h2>
<p>For most <strong>NNs</strong> today, they are trained to minimize a designed loss function, which quantizes the ability of the model.</p>
<p>Though being intuitive and reasonable, after a model is trained for a long time, a phenomenon called <strong>overfitting</strong> occurs. The model performed so well in the training set, that it behaves badly with more generalized data - whose distribution may differ from the training set.</p>
<p>There are several tricks we can adopt in training, to mitigate overfitting.</p>
<p>They are often known as <strong>regularization</strong></p>
<h3 id="weight-penalty">Weight Penalty</h3>
<p>The measurement of complexity:</p>
<ul>
<li>Number of parameter</li>
<li>Absolute value of parameters</li>
</ul>
<h3 id="dropout">Dropout</h3>
<p><strong>Dropout</strong> works in the training phase:</p>
<ol>
<li>In each batch, <strong>randomly</strong> disable some neurons with ratio <em>k</em>. The output of these deleted neurons became 0.</li>
<li>Multiply the output with <em>k</em>: $o = o * k$ to rectify</li>
</ol>
<p>The reason behind <strong>dropout</strong>:</p>
<h4 id="average">Average</h4>
<p>It can be interpreted as a special case of <strong>ensemble</strong> , taking the average of output of expertises(the active neurons)</p>
<h4 id="reduce-co-relation-between-neurons">Reduce Co-relation between neurons</h4>
<h4 id="evolution-theory">Evolution theory</h4>
<p>Consider the <strong>disable action</strong> as the environment mutation, the model adapts to this mutation(new environment) by breeding new breeds(the different combination of active neurons)</p>
<h4 id="variant-vanilla-dropout">Variant: vanilla dropout</h4>
<h2 id="normalization">Normalization</h2>
<table>
<thead>
<tr>
<th style="text-align:left">Notation</th>
<th style="text-align:left">Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">$B$</td>
<td style="text-align:left">Batch size</td>
</tr>
<tr>
<td style="text-align:left">$S$</td>
<td style="text-align:left">Sequence length</td>
</tr>
<tr>
<td style="text-align:left">$$</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
<h3 id="batch-normalization">Batch Normalization</h3>
<p>Normalization across the $B$ dimension:</p>
<h3 id="layer-normalization">Layer Normalization</h3>
<h3 id="group-normalization">Group Normalization</h3>
<p>tan h: 当 |x| 比较小 时，接近线性网络</p>
<p>手段：</p>
<ul>
<li>向损失函数中引入正则项，将模型参数的范数作为惩罚</li>
<li>Dropout: 训练时，随机屏蔽（置0）并对结果进行 scale
<ul>
<li>原理：Don&rsquo;t rely on any one feature(neuron), spread out weights</li>
<li>随机淘汰网络中的一些单元，因此训练时，每层不会对任意一个神经元施加 <strong>太多权重</strong>，这种分散权重的方式防止了过拟合</li>
<li>迫使同层节点对输出承担或多或少的责任，增强模型的泛化性，因为它不会太依赖某些局部的特征</li>
</ul>
</li>
<li>Data augmentation
<ul>
<li>增加数据集的泛化性</li>
</ul>
</li>
<li>Early stopping
<ul>
<li>在权重 overfit 之前结束，但 error 较高</li>
</ul>
</li>
<li></li>
</ul>
<h2 id="normalize">Normalize</h2>
<p>对于随机输入数据，会导致<strong>成本函数</strong>对每个维度的scale 不一致(elongated)，导致参数调整出现很多 oscillate</p>
<ul>
<li>z-score</li>
<li>min-max
![[Attachments/AI/Techniques of Training NNs/IMG-20240121133309891.png]]</li>
<li>softmax: normalized exponential function</li>
</ul>
<h3 id="batch-norm">Batch Norm</h3>
<p>对<strong>每一批</strong>训练数据进行归一化，</p>
<p>effect:</p>
<ul>
<li><strong>reduce shift</strong> on train data</li>
<li>增加模型的鲁棒性，提升训练速度</li>
</ul>
<p>在 z/a 上作用</p>
<p>why work?</p>
<ul>
<li>learning on shifting input distribution: 偏移在神经网络中会产生累积，导致后面的层的输入不稳定</li>
</ul>
<h3 id="layer-norm">Layer Norm</h3>
<p>不是全量数据集，因为容易过拟合</p>
<h2 id="bias">Bias</h2>
<p>Inductive bias</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
