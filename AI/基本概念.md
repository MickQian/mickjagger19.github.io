## Activation Function 激活函数
非线性变换
* sigmoid
* tanh
* relu
* prelu
* elu
* maxout


## Normalization 归一化
* z-score
* min-max
	![[Pasted image 20230510221729.png]]
* softmax: normalized exponential function  

## Feed
### Feed forward


### Feed back