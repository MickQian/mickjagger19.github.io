机器学习的种类： 
* 神经网络
* 传统机器学习: SVM
* 决策树，随机森林


## Activation Function 激活函数
**非线性**变换
* sigmoid
* tanh
* relu
* prelu
* elu
* maxout


## Vanishing/Exploding  Gradients
原因：梯度相乘带来的收敛/发散

手段：
	* 正确的权重初始化




## Overfitting

cause: 数据/模型复杂度 比 过小
数据规模越小，泛化性越差，会导致数据集中的共有的/非泛化特征被学习

在相对较少的数据集上训练大型网络
为了防止 过拟合，可以从 数据集/模型训练两个角度思考


* 减少参数
* 惩罚复杂性: weight decay
	* $Loss = MSE + wd * sum(w^2) $
	* 把参数的norm加入 Loss 函数中(l2 norm)
	* 如何决定 wd(weight decay)?  0.1 左右

* ensemble: 在同一数据集上拟合不同模型，对每个模型的预测取平均值
	* 问题：时间长



 

## Gram Matrix
半正定，核函数



## Logistic regression







